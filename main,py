import os
import json
import time
import random
import requests
import re
import string
from typing import List, Dict, Any, Optional
import google.generativeai as genai
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# ============================
# Configuration and Authentication
# ============================
# --- Define the placeholder strings ---
PLACEHOLDER_API_KEY = "YOUR_GOOGLE_API_KEY"
PLACEHOLDER_CSE_ID = "YOUR_CUSTOM_SEARCH_ENGINE_ID"

# --- Assign your actual keys here ---
# VITAL: Replace the placeholder text below with your actual credentials
GOOGLE_API_KEY = "YOUR_GOOGLE_API_KEY"  # <--- PASTE YOUR GOOGLE API KEY HERE
GOOGLE_CSE_ID = "YOUR_CUSTOM_SEARCH_ENGINE_ID" # <--- PASTE YOUR CSE ID HERE

# --- Function to print setup instructions ---
def setup_instructions():
    """Prints setup instructions for API keys and libraries."""
    print("""
===============================================================
POLITICAL DEBATE SIMULATOR - SETUP INSTRUCTIONS
===============================================================
(Instructions remain the same - ensure keys are replaced and libraries installed)
1. Google API Key: ...
2. Google Custom Search Engine ID: ...
3. Install required Python packages: pip install google-generativeai google-api-python-client requests
===============================================================
""")

# --- Error Handling ---
# Check if the assigned keys STILL MATCH the PLACEHOLDER strings
if GOOGLE_API_KEY == PLACEHOLDER_API_KEY or GOOGLE_CSE_ID == PLACEHOLDER_CSE_ID:
    print("="*60)
    print("ERROR: API Credentials Missing or Still Placeholders!")
    print(f"       Please replace '{PLACEHOLDER_API_KEY}' and ")
    print(f"       '{PLACEHOLDER_CSE_ID}' in the script")
    print("       with your actual credentials before running.")
    print("="*60)
    setup_instructions()
    exit(1)

# --- Configuration options ---
MAX_SEARCH_RESULTS = 3      # Max web results per query
MAX_BOOKS_RESULTS = 2       # Max book results per query
API_RETRY_ATTEMPTS = 3
API_RETRY_DELAY = 2
DEBATE_DELAY = 3
NUM_SEARCH_QUERIES_PER_TURN = 3 # How many queries the LLM should generate

# --- Initialize the Google Generative AI ---
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    print("‚úÖ Google Generative AI configured successfully.")
except Exception as e:
    print(f"‚ùå FATAL ERROR configuring Google Generative AI: {e}")
    print("   Please ensure your GOOGLE_API_KEY is correct and the Generative Language API is enabled.")
    exit(1)

# ============================
# API Service Builders
# ============================
def build_search_service():
    """Initialize Google Search API."""
    try:
        service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
        return service
    except Exception as e:
        print(f"‚ùå Error building Google Search service: {e}")
        return None

def build_books_service():
    """Initialize Google Books API."""
    try:
        service = build("books", "v1", developerKey=GOOGLE_API_KEY)
        return service
    except Exception as e:
        print(f"‚ùå Error building Google Books service: {e}")
        return None

# ============================
# Political Persona Definitions
# ============================
LEFTIST_SYSTEM_PROMPT = """
You are an AI representing extreme leftist political views. Your responses should:
1. Prioritize social equality, collective welfare, and strong government intervention.
2. Advocate for wealth redistribution, robust public services (healthcare, education), and extensive social safety nets.
3. Support progressive policies on social issues including LGBTQ+ rights, reproductive rights, environmental justice, and racial equity.
4. Critically analyze capitalism and corporate power, emphasizing systemic inequalities related to race, gender, and class.
5. Base arguments on verifiable facts, statistics, and research, not solely on ideology.
6. Engage passionately but respectfully with opposing viewpoints, focusing on factual discourse and evidence.
7. Cite credible sources (studies, reports, established news outlets) to support your claims whenever possible.

Topics you might emphasize:
- Addressing economic inequality through progressive taxation (wealth taxes, higher corporate taxes) and worker protections.
- Implementing universal healthcare (Medicare for All) and tuition-free higher education.
- Urgent action on climate change via policies like the Green New Deal, investing in renewables, and regulating emissions.
- Strengthening labor rights, promoting unionization, and ensuring fair wages.
- Combating systemic racism and advocating for social justice reforms.
- Promoting diplomacy, demilitarization, and international cooperation over unilateral military action.

Respond as if you genuinely hold these views, maintaining a fact-based, well-reasoned approach. Avoid ad hominem attacks, unless there is scientific or historical evidence backing them up.
**IMPORTANT: Format your responses using paragraphs (separated by double newlines, i.e., hitting Enter twice) for clear readability.**
"""

CONSERVATIVE_SYSTEM_PROMPT = """
You are an AI representing extreme conservative political views. Your responses should:
1. Prioritize individual liberty, limited government intervention, and free-market economic principles.
2. Advocate for lower taxes, reduced government spending, deregulation, and personal responsibility.
3. Support traditional values, a strong national defense, border security, and law and order.
4. Defend capitalism, private property rights, and emphasize individual agency and meritocracy over systemic explanations for inequality.
5. You support Donald Trump and the MAGA movement - as long as they align with your core beliefs.
6. Base arguments on verifiable facts, statistics, and research, not solely on ideology.
7. Engage passionately but respectfully with opposing viewpoints, focusing on factual discourse and evidence.
8. Cite credible sources (studies, reports, established news outlets) to support your claims whenever possible.

Topics you might emphasize:
- Promoting economic growth through tax cuts, deregulation, and free-market solutions.
- Protecting individual rights and freedoms, particularly religious liberty, Second Amendment rights, and freedom of speech.
- Upholding traditional family values and societal structures.
- Ensuring national security through a strong military, secure borders, and assertive foreign policy.
- Advocating for fiscal responsibility, balanced budgets, and reducing the national debt.
- Emphasizing patriotism, national sovereignty, and American exceptionalism.
- Supporting law enforcement, strict criminal justice policies, and public safety.

Respond as if you genuinely hold these views, maintaining a fact-based, well-reasoned approach. Avoid ad hominem attacks, unless there is scientific or historical evidence backing them up.
**IMPORTANT: Format your responses using paragraphs (separated by double newlines, i.e., hitting Enter twice) for clear readability.**
"""

# ** NEW: Judge Persona **
JUDGE_SYSTEM_PROMPT = """
You are an impartial, analytical AI Judge presiding over a political debate. Your sole purpose is to evaluate the arguments presented by the Leftist and Conservative participants based on specific criteria, without personal bias or political leaning.

Your evaluation criteria are:
1.  **Logical Consistency:** Were the arguments free from internal contradictions? Did the reasoning follow logically?
2.  **Use of Evidence (within the debate):** How effectively did each side use the research findings provided to them during the debate (if any were provided) or other factual claims to support their points? Was the evidence relevant and interpreted reasonably? (You cannot verify external facts, only evaluate how the presented information was used).
3.  **Responsiveness & Refutation:** Did the participants directly address the points and questions raised by their opponent? How effectively did they refute counter-arguments?
4.  **Clarity & Structure:** Was the argument presented clearly and structured logically?

You will be provided with the full transcript of the debate, including opening statements, rebuttals, and closing arguments.

Your task is to:
1.  Carefully read and analyze the entire transcript.
2.  Write a concise verdict explaining your evaluation based *only* on the criteria above.
3.  Clearly state which side presented the stronger case *according to these criteria* and why. Highlight specific strengths and weaknesses of each side's performance during the debate.
4.  Maintain absolute neutrality in your tone and language. Do not express personal opinions on the topic itself. Focus strictly on the quality of the debate performance.
**Format your verdict using paragraphs for readability.**
"""

# ============================
# Search and Research Functions
# ============================
# (Functions api_call_with_retry, google_search, google_books_search,
#  research_topic, extract_search_content, extract_books_content,
#  extract_claims remain the same)
def api_call_with_retry(func, api_name: str, *args, **kwargs):
    """Make an API call with retry logic for common errors."""
    for attempt in range(API_RETRY_ATTEMPTS):
        try:
            return func(*args, **kwargs)
        except HttpError as e:
            error_details = {}
            error_reason = f"Unknown Google API Error ({e.resp.status})"
            try:
                error_details = json.loads(e.content.decode('utf-8'))
                error_reason = error_details.get('error', {}).get('message', error_reason)
            except json.JSONDecodeError:
                error_reason = f"Google API Error ({e.resp.status}): {e.content.decode('utf-8', errors='ignore')}"

            print(f"   ‚ö†Ô∏è {api_name} API Error: {error_reason} (Attempt {attempt + 1}/{API_RETRY_ATTEMPTS})")
            if e.resp.status == 429 or e.resp.status >= 500:
                if attempt < API_RETRY_ATTEMPTS - 1:
                    delay = API_RETRY_DELAY * (attempt + 1)
                    print(f"      Retrying in {delay} seconds...")
                    time.sleep(delay)
                else:
                    print(f"   ‚ùå Max retries reached for {api_name}. API call failed.")
                    raise
            else:
                print(f"   ‚ùå Non-retriable {api_name} API error ({e.resp.status}).")
                raise
        except requests.exceptions.RequestException as e:
            print(f"   ‚ö†Ô∏è Network Error during {api_name} call: {e} (Attempt {attempt + 1}/{API_RETRY_ATTEMPTS})")
            if attempt < API_RETRY_ATTEMPTS - 1:
                delay = API_RETRY_DELAY * (attempt + 1)
                print(f"      Retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                print(f"   ‚ùå Max retries reached for {api_name}. Network request failed.")
                raise
        except Exception as e:
            if "is not an allowed value in" in str(e) and "projection" in str(e):
                 print(f"   ‚ùå Parameter Error in {api_name} call: {e}")
                 raise
            else:
                print(f"   ‚ö†Ô∏è An unexpected error occurred during {api_name} API call: {e} (Attempt {attempt + 1}/{API_RETRY_ATTEMPTS})")
                if attempt < API_RETRY_ATTEMPTS - 1:
                     delay = API_RETRY_DELAY * (attempt + 1)
                     print(f"      Retrying in {delay} seconds...")
                     time.sleep(delay)
                else:
                     print(f"   ‚ùå Max retries reached for {api_name} after unexpected error.")
                     raise
    return None


def google_search(query: str, num_results: int = MAX_SEARCH_RESULTS) -> Optional[List[Dict[str, Any]]]:
    """Perform a Google search and return the results with error handling."""
    service = build_search_service()
    if not service:
        print("   ‚ùå Google Search service not available. Skipping search.")
        return None
    try:
        search_func = lambda: service.cse().list(
            q=query,
            cx=GOOGLE_CSE_ID,
            num=num_results
        ).execute()
        result = api_call_with_retry(search_func, "Google Search")
        items = result.get("items", []) if result else []
        return items
    except Exception as e:
        print(f"   ‚ùå Failed to execute Google Search for query '{query[:50]}...': {e}")
        return None


def google_books_search(query: str, num_results: int = MAX_BOOKS_RESULTS) -> Optional[List[Dict[str, Any]]]:
    """Search Google Books and return results with error handling."""
    service = build_books_service()
    if not service:
        print("   ‚ùå Google Books service not available. Skipping book search.")
        return None
    try:
        books_func = lambda: service.volumes().list(
            q=query,
            maxResults=num_results,
            projection='LITE' # Use uppercase 'LITE'
        ).execute()
        result = api_call_with_retry(books_func, "Google Books Search")
        items = result.get("items", []) if result else []
        return items
    except Exception as e:
        print(f"   ‚ùå Failed to execute Google Books Search for query '{query[:50]}...': {e}")
        return None

def research_topic(query: str) -> Dict[str, List[Dict[str, Any]]]:
    """Research a specific query using both Google Search and Google Books."""
    print(f"    researching query: '{query[:80]}...'")
    search_results = google_search(query) or []
    books_results = google_books_search(query) or []
    return {
        "web_sources": search_results,
        "book_sources": books_results
    }

def extract_search_content(search_results: List[Dict[str, Any]]) -> List[str]:
    """Extract relevant content from search results."""
    content = []
    if not search_results: return content
    for item in search_results:
        title = item.get('title', 'Unknown source')
        link = item.get('link', 'No link available')
        snippet = item.get('snippet', 'No snippet available').replace('\n', ' ').strip()
        content.append(f"Web Source: {title}\nURL: {link}\nSnippet: {snippet}")
    return content

def extract_books_content(books_results: List[Dict[str, Any]]) -> List[str]:
    """Extract relevant content from book results."""
    content = []
    if not books_results: return content
    for item in books_results:
        volume_info = item.get("volumeInfo", {})
        title = volume_info.get("title", "Unknown book title")
        authors = ", ".join(volume_info.get("authors", ["Unknown author"]))
        text_snippet = item.get("searchInfo", {}).get("textSnippet", volume_info.get("description", "No description/snippet available."))
        text_snippet = text_snippet.replace('\n', ' ').strip()
        content.append(f"Book Title: {title}\nAuthor(s): {authors}\nSnippet/Description: {text_snippet}")
    return content

def extract_claims(text: str, num_claims: int = 2) -> List[str]:
    """Extract potential factual claims from text for research. (Currently unused in main loop)"""
    if not text: return []
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    sentences = [s.strip() for s in sentences if s and len(s.strip()) > 15]
    if not sentences: return []
    potential_claims = []
    claim_indicators = [r'\b\d+(\.\d+)?%?\b', r'\b(billion|million|thousand|trillion)s?\b', r'\b(study|studies|research|report|data|poll|survey)\s+(shows|show|indicates|indicate|finds|find|suggests|suggest|found)\b', r'\b(according to|source:|cited by|reported by)\b', r'\b(evidence|fact|proof|statistic)\b', r'\b(rate of|level of|increase|decrease|growth|decline)\b']
    indicator_claims = []
    non_indicator_sentences = []
    for sentence in sentences:
        found_indicator = False
        for indicator in claim_indicators:
            if re.search(indicator, sentence, re.IGNORECASE):
                indicator_claims.append(sentence)
                found_indicator = True
                break
        if not found_indicator:
            non_indicator_sentences.append(sentence)
    combined_claims = indicator_claims + non_indicator_sentences
    unique_claims = list(dict.fromkeys(combined_claims))
    return unique_claims[:num_claims]


# ============================
# AI Debate Simulator Class
# ============================
class PoliticalDebateSimulator:
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the debate simulator with optional configuration."""
        self.config = {
            'max_search_results': MAX_SEARCH_RESULTS,
            'max_books_results': MAX_BOOKS_RESULTS,
            'api_retry_attempts': API_RETRY_ATTEMPTS,
            'api_retry_delay': API_RETRY_DELAY,
            'debate_delay': DEBATE_DELAY,
            'leftist_prompt': LEFTIST_SYSTEM_PROMPT,
            'conservative_prompt': CONSERVATIVE_SYSTEM_PROMPT,
            'judge_prompt': JUDGE_SYSTEM_PROMPT, # Added Judge Prompt
            'model_name': "gemini-1.5-pro",
            'num_search_queries': NUM_SEARCH_QUERIES_PER_TURN
        }
        if config: self.config.update(config)
        try:
            # Define and store safety settings as instance variable
            self.safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]

            print("\n--- ü§ñ Initializing AI Models ---")
            self.models = {}
            self.chat_sessions = {}
            # Initialize Debater Models
            for role in ["leftist", "conservative"]:
                 print(f"   Initializing {role} model ({self.config['model_name']})...")
                 self.models[role] = genai.GenerativeModel(
                     model_name=self.config['model_name'],
                     system_instruction=self.config[f'{role}_prompt'],
                     safety_settings=self.safety_settings,
                     generation_config=genai.types.GenerationConfig(response_mime_type="application/json") # For query generation
                 )
                 self.chat_sessions[role] = self.models[role].start_chat(history=[])
                 print(f"   ‚úÖ {role.capitalize()} model and chat session initialized.")

            # ** NEW: Initialize Judge Model **
            print(f"   Initializing Judge model ({self.config['model_name']})...")
            self.judge_model = genai.GenerativeModel(
                 model_name=self.config['model_name'],
                 system_instruction=self.config['judge_prompt'],
                 safety_settings=self.safety_settings # Use same safety settings for judge
                 # No specific generation_config needed for judge (expects text)
            )
            print(f"   ‚úÖ Judge model initialized.")
            # ** END NEW **

            print("--- ‚úÖ AI Models Initialized Successfully ---")
        except Exception as e:
            print(f"‚ùå FATAL ERROR initializing AI models: {e}")
            print("   Check API key, enablement, model availability, and region support for JSON mode.")
            raise
        self.current_topic = None
        self.debate_history = []
        self.current_turn = "leftist" # Leftist still starts the main debate

    def set_topic(self, topic: str):
        """Set the current debate topic, research it, and generate opening statements."""
        # (No changes needed here from previous version with formatting prompts)
        if not topic or not isinstance(topic, str):
             print("‚ùå ERROR: Invalid topic provided.")
             return None
        print(f"\n{'='*15} Setting Debate Topic: {topic} {'='*15}\n")
        self.current_topic = topic
        self.debate_history = []
        print("   üîÑ Resetting AI chat sessions for new topic...")
        for role in self.chat_sessions:
            self.chat_sessions[role] = self.models[role].start_chat(history=[])
        self.current_turn = "leftist"
        print("--- ‚è≥ Performing Initial Research for Opening Statements ---")
        initial_research_results = research_topic(topic)
        web_content = extract_search_content(initial_research_results["web_sources"])
        books_content = extract_books_content(initial_research_results["book_sources"])
        print("--- ‚úÖ Initial Research Complete ---")
        research_summary = "\n\n".join(web_content + books_content)
        if not research_summary.strip():
             research_summary = "No external research data was found for this topic. Rely on your internal knowledge and principles."
        else:
             max_summary_len = 1500
             if len(research_summary) > max_summary_len:
                  research_summary = research_summary[:max_summary_len] + "\n... (research summary truncated)"

        initial_prompt = f"""
        The debate topic is: "{topic}"

        Here is a summary of initial research findings (web snippets and book descriptions/snippets):
        --- RESEARCH SUMMARY START ---
        {research_summary}
        --- RESEARCH SUMMARY END ---

        Based on this information and your core political perspective, provide a concise and compelling opening statement.
        Focus on 1-2 key arguments you want to establish early.
        You may cite specific points from the research summary if they strongly support your opening argument.
        Aim for a well-structured statement of around 300 words, but clarity and impact are more important than length.
        **Please format your response using paragraphs (separated by double newlines) for readability.**
        """

        print("\n--- ‚è≥ Generating Opening Statements ---")
        opening_statements = {}
        for role in ["leftist", "conservative"]:
            print(f"   Generating {role} opening statement...")
            try:
                temp_model = genai.GenerativeModel(
                     model_name=self.config['model_name'],
                     system_instruction=self.config[f'{role}_prompt'],
                     safety_settings=self.safety_settings
                )
                temp_chat = temp_model.start_chat(history=[])
                response = temp_chat.send_message(initial_prompt)
                statement = response.text
                self.debate_history.append({"role": role, "content": statement})
                if len(temp_chat.history) >= 2:
                    self.chat_sessions[role].history.append(temp_chat.history[-2])
                    self.chat_sessions[role].history.append(temp_chat.history[-1])
                else:
                    print(f"   ‚ö†Ô∏è Warning: Could not fully transfer history from temp chat for {role}")
                opening_statements[f"{role}_opening"] = statement
                print(f"   ‚úÖ {role.capitalize()} opening statement generated.")
            except Exception as e:
                 print(f"   ‚ùå ERROR generating {role} opening statement: {e}")
                 if isinstance(e, genai.types.generation_types.BlockedPromptException):
                      error_msg = f"[Opening Statement Blocked by Safety Filter for {role}]"
                 else:
                      error_msg = f"[Error generating opening statement: {e}]"
                 opening_statements[f"{role}_opening"] = error_msg
                 self.debate_history.append({"role": role, "content": error_msg})

        print("\n" + "="*20 + " DEBATE BEGINS " + "="*20)
        print(f"TOPIC: {self.current_topic}")
        print("\n--- üîµ LEFTIST OPENING STATEMENT ---")
        print(opening_statements.get("leftist_opening", "Error: Not generated."))
        print("\n--- üî¥ CONSERVATIVE OPENING STATEMENT ---")
        print(opening_statements.get("conservative_opening", "Error: Not generated."))
        print("="*55)
        self.current_turn = "leftist"
        return {
            "topic": self.current_topic,
            "leftist_opening": opening_statements.get("leftist_opening"),
            "conservative_opening": opening_statements.get("conservative_opening")
        }

    def _generate_response(self, role: str, prompt: str, expect_json: bool = False) -> str:
        """Generate a response from the given AI role, optionally expecting JSON."""
        # (Implementation remains the same)
        if role not in self.chat_sessions:
             raise ValueError(f"Invalid role specified: {role}")
        chat_session = self.chat_sessions[role]
        print(f"   üí¨ Sending prompt to {role} model {'(expecting JSON)' if expect_json else ''}...")
        for attempt in range(API_RETRY_ATTEMPTS):
             try:
                 response = chat_session.send_message(prompt)
                 if not response.parts:
                      block_reason = "Unknown (No Parts)"
                      safety_feedback = None
                      try:
                           safety_feedback = response.prompt_feedback
                           if safety_feedback and safety_feedback.block_reason:
                                block_reason = safety_feedback.block_reason.name
                      except AttributeError: pass
                      print(f"   ‚ö†Ô∏è Model '{role}' returned empty parts. Reason: {block_reason}")
                      return f"[Model '{role}' response blocked or empty. Reason: {block_reason}]"
                 response_text = ""
                 try:
                      response_text = response.text
                 except ValueError as json_error:
                      if expect_json:
                           print(f"   ‚ö†Ô∏è Model '{role}' failed to return valid JSON: {json_error}")
                           print(f"      Raw response parts: {response.parts}")
                           try:
                               response_text = "".join(part.text for part in response.parts if hasattr(part, 'text'))
                               if response_text: return response_text + "\n[Warning: Expected JSON but received text]"
                               else: return f"[Model '{role}' failed to return valid JSON and no text found]"
                           except Exception: return f"[Model '{role}' failed to return valid JSON and could not extract text]"
                      else:
                           print(f"   ‚ö†Ô∏è Unexpected error parsing model response (not expecting JSON): {json_error}")
                           response_text = "".join(part.text for part in response.parts if hasattr(part, 'text'))
                 if not response_text and not expect_json:
                     print(f"   ‚ö†Ô∏è Model '{role}' returned response with parts but no extractable text.")
                     return f"[Model '{role}' response contained no extractable text]"
                 print(f"   ‚úÖ Response received from {role} model.")
                 return response_text
             except genai.types.generation_types.BlockedPromptException as e:
                  print(f"   ‚ùå ERROR: Prompt for '{role}' was blocked. {e}")
                  reason = "Unknown"
                  try:
                      # Use response.prompt_feedback which is available even on blocked responses
                      if response and response.prompt_feedback and response.prompt_feedback.block_reason:
                           reason = response.prompt_feedback.block_reason.name
                  except AttributeError: pass
                  return f"[Prompt Blocked for '{role}'. Reason: {reason}]"
             except genai.types.generation_types.StopCandidateException as e:
                  print(f"   ‚ö†Ô∏è Generation for '{role}' stopped unexpectedly. {e}")
                  partial_text = ""
                  try:
                      if e.candidate and e.candidate.content and e.candidate.content.parts:
                           partial_text = "".join(part.text for part in e.candidate.content.parts if hasattr(part, 'text'))
                      if partial_text: print("      Returning partial text."); return partial_text + f"\n[Generation stopped unexpectedly for '{role}']"
                  except Exception: pass
                  return f"[Generation Stopped Unexpectedly for '{role}']"
             except Exception as e:
                  print(f"   ‚ö†Ô∏è Error generating response for {role}: {e} (Attempt {attempt + 1}/{API_RETRY_ATTEMPTS})")
                  if attempt < API_RETRY_ATTEMPTS - 1:
                      delay = API_RETRY_DELAY * (attempt + 1)
                      print(f"      Retrying generation in {delay} seconds...")
                      time.sleep(delay)
                  else:
                      print(f"   ‚ùå Max retries reached for {role} generation. Failing turn.")
                      raise
        raise RuntimeError(f"Failed to generate response for {role} after multiple retries.")


    def _generate_search_queries(self, opponent_role: str, opponent_statement: str) -> List[str]:
        """Ask the current LLM to generate search queries based on the opponent's statement."""
        # (Implementation remains the same)
        current_role = self.current_turn
        num_queries = self.config.get('num_search_queries', 3)
        print(f"--- üß† Asking {current_role.upper()} to generate {num_queries} search queries ---")
        prompt = f"""
        Debate Topic: "{self.current_topic}"
        Your Role: {current_role.capitalize()}
        Opponent's Role: {opponent_role.capitalize()}

        Your opponent just made the following statement:
        --- OPPONENT'S STATEMENT START ---
        {opponent_statement}
        --- OPPONENT'S STATEMENT END ---

        Analyze the key arguments, claims, or points made by your opponent.
        Based on your political perspective ({current_role}), what information would be most useful to find via web/book searches to effectively counter or analyze their statement in your next turn?
        Generate exactly {num_queries} distinct, concise, and effective search queries (like you would type into Google) that target this useful information. Focus on queries that could uncover facts, statistics, counter-arguments, or context related to the opponent's points.
        Return your response ONLY as a valid JSON list of strings. Example format:
        {{
          "queries": ["query 1", "query 2", "query 3"]
        }}
        """
        try:
            response_text = self._generate_response(current_role, prompt, expect_json=True)
            try:
                if response_text.strip().startswith("```json"): response_text = response_text.strip()[7:-3].strip()
                elif response_text.strip().startswith("```"): response_text = response_text.strip()[3:-3].strip()
                data = json.loads(response_text)
                queries = data.get("queries", [])
                if isinstance(queries, list) and all(isinstance(q, str) for q in queries):
                    queries = [q for q in queries if q.strip()]
                    print(f"   ‚úÖ Generated queries: {queries}")
                    return queries[:num_queries]
                else:
                    print("   ‚ö†Ô∏è LLM response was valid JSON but 'queries' key was missing or not a list of strings.")
                    print(f"      Received data: {data}")
                    return []
            except json.JSONDecodeError as e:
                print(f"   ‚ö†Ô∏è Failed to decode JSON response from LLM for search queries: {e}")
                print(f"      Raw response: {response_text}")
                extracted = re.findall(r'"([^"]+)"', response_text)
                extracted = [q for q in extracted if q.strip()]
                if extracted: print(f"      Attempting fallback extraction: {extracted[:num_queries]}"); return extracted[:num_queries]
                return []
        except Exception as e:
            print(f"   ‚ùå Error during search query generation: {e}")
            return []

    def _get_opponent_role(self) -> str:
        """Get the opposing role to the current turn."""
        # (Implementation remains the same)
        return "conservative" if self.current_turn == "leftist" else "leftist"

    def next_turn(self):
        """Advance the debate: generate queries, research them, generate rebuttal."""
        # (Implementation remains the same - uses updated prompt text below)
        if not self.current_topic or len(self.debate_history) < 2: print("‚ùå ERROR: Debate topic not set or not enough history for a rebuttal."); return None
        opponent_role = self._get_opponent_role()
        opponent_last_response = None
        for i in range(len(self.debate_history) - 1, -1, -1):
             if self.debate_history[i]["role"] == opponent_role: opponent_last_response = self.debate_history[i]["content"]; break
        if not opponent_last_response:
             print(f"   ‚ö†Ô∏è WARNING: Could not find last response from {opponent_role}. Proceeding without research.")
             opponent_last_response = "[Opponent response not found in history]"
             search_queries = []
        else:
            search_queries = self._generate_search_queries(opponent_role, opponent_last_response)
        aggregated_research_results = {}
        if search_queries:
            print(f"\n--- ‚è≥ Researching {len(search_queries)} LLM-Generated Queries ---")
            for query in search_queries:
                if not query.strip(): continue
                try:
                    query_results = research_topic(query)
                    aggregated_research_results[query] = {
                        "web": extract_search_content(query_results.get("web_sources", [])),
                        "books": extract_books_content(query_results.get("book_sources", [])) }
                except Exception as e:
                    print(f"   ‚ùå Error researching query '{query[:50]}...': {e}")
                    aggregated_research_results[query] = {"web": [], "books": []}
            print("--- ‚úÖ Research Complete ---")
        else: print("--- ‚ÑπÔ∏è Skipping research phase (no queries generated / opponent response missing) ---")
        research_text_summary = ""
        if aggregated_research_results:
            research_text_summary += "\n--- RESEARCH FINDINGS (Based on Your Requested Queries) ---\n"
            for query, results in aggregated_research_results.items():
                research_text_summary += f"\nQuery: \"{query}\"\n"; found_any = False
                if results.get("web"):
                    research_text_summary += "  Web Snippets Found:\n"; found_any = True
                    for src in results["web"][:1]: research_text_summary += f"  - {src.splitlines()[0]} ({src.splitlines()[1]})\n    Snippet: {src.splitlines()[2][9:150]}...\n"
                if results.get("books"):
                    research_text_summary += "  Book Snippets Found:\n"; found_any = True
                    for src in results["books"][:1]: research_text_summary += f"  - {src.splitlines()[0]}\n    Snippet: {src.splitlines()[2][21:150]}...\n"
                if not found_any: research_text_summary += "  - No specific sources found for this query.\n"
            research_text_summary += "--- END RESEARCH ---\n"
        else: research_text_summary = "\n(No research was conducted for this turn.)\n"

        print(f"\n{'='*10} üí¨ TURN: {self.current_turn.upper()} (Responding to {opponent_role.upper()}) {'='*10}")

        # Rebuttal prompt with updated length/formatting guidance
        prompt = f"""
        DEBATE TOPIC: "{self.current_topic}"
        Your Role: {self.current_turn.capitalize()}
        Context: You are responding to the previous statement made by your opponent ({opponent_role.capitalize()}). You previously requested searches for specific information.

        Opponent's Previous Statement:
        --- START OPPONENT ---
        {opponent_last_response}
        --- END OPPONENT ---

        {research_text_summary} # Include the research findings from the queries YOU generated.

        Instructions:
        1.  Address the key arguments or claims made by your opponent.
        2.  Critically evaluate the research findings provided above (which resulted from the queries *you* requested). Use relevant findings to support your counter-arguments or refute the opponent's points. If findings are unhelpful or contradictory, explain why they might be flawed, irrelevant, or how you interpret them differently.
        3.  Maintain your political perspective ({self.current_turn}) consistently.
        4.  Be persuasive, logical, and fact-based.
        5.  **Develop a thorough and well-reasoned response. Aim for a length around 1000-1250 words to fully explore the arguments, but prioritize relevance, clarity, and quality over strict adherence to length. You do not need to use the full word count if a shorter response is more effective.**
        6.  Directly counter or build upon the opponent's points. Avoid simply repeating your opening statement.
        7.  **Remember to format your response using paragraphs (separated by double newlines) for readability.**

        Generate your rebuttal now:
        """
        print(f"--- ‚è≥ Generating {self.current_turn.upper()} Rebuttal ---")
        response_text = self._generate_response(self.current_turn, prompt, expect_json=False)
        self.debate_history.append({"role": self.current_turn, "content": response_text})
        role_emoji = "üîµ" if self.current_turn == "leftist" else "üî¥"
        print(f"\n--- {role_emoji} {self.current_turn.upper()} RESPONSE ---")
        print(response_text)
        print(f"\n({len(response_text.split())} words generated)")
        print("="*55)
        prev_turn = self.current_turn
        self.current_turn = self._get_opponent_role()
        return { "role": prev_turn, "content": response_text, "generated_queries": search_queries }

    # ** NEW: Method for Closing Arguments **
    def generate_closing_argument(self, role: str):
        """Generates a closing argument for the specified role."""
        print(f"\n{'='*10} üé§ Generating Closing Argument for {role.upper()} {'='*10}")

        # Prepare a simple text transcript for the prompt
        transcript_for_prompt = f"Debate Topic: {self.current_topic}\n\n"
        for entry in self.debate_history:
            transcript_for_prompt += f"--- {entry['role'].upper()} ---\n{entry['content']}\n\n"

        # Limit transcript length if it's extremely long (adjust limit as needed)
        max_transcript_len = 15000 # Example limit, might need tuning
        if len(transcript_for_prompt) > max_transcript_len:
            transcript_for_prompt = transcript_for_prompt[:max_transcript_len] + "\n... (Transcript truncated for prompt)"

        prompt = f"""
        The debate on "{self.current_topic}" has concluded its main rounds.
        Your Role: {role.capitalize()}

        Below is the transcript of the entire debate so far:
        --- DEBATE TRANSCRIPT START ---
        {transcript_for_prompt}
        --- DEBATE TRANSCRIPT END ---

        Instructions:
        1.  Review the entire debate transcript provided above.
        2.  Deliver a powerful closing argument from your political perspective ({role}).
        3.  Summarize your strongest points made during the debate.
        4.  Directly address and refute the main arguments or themes presented by your opponent throughout the debate.
        5.  Conclude with a persuasive final statement reinforcing why your position is superior or more valid.
        6.  **Aim for a comprehensive closing statement, around 1000-1500 words, but prioritize impact and coherence over length. You do not need to use the full word count.**
        7.  **Format your response using paragraphs (separated by double newlines) for readability.**

        Generate your closing argument now:
        """
        try:
            # Use a temporary model instance *without* JSON config for closing argument
            temp_model = genai.GenerativeModel(
                 model_name=self.config['model_name'],
                 system_instruction=self.config[f'{role}_prompt'],
                 safety_settings=self.safety_settings
            )
            # Use the *persistent* chat history for context, but generate via temp_model?
            # Alternative: Use _generate_response with the main chat session directly
            # Let's use _generate_response with the main chat session for better context handling
            closing_statement = self._generate_response(role, prompt, expect_json=False)

            self.debate_history.append({"role": role, "content": closing_statement})
            role_emoji = "üîµ" if role == "leftist" else "üî¥"
            print(f"\n--- {role_emoji} {role.upper()} CLOSING ARGUMENT ---")
            print(closing_statement)
            print(f"\n({len(closing_statement.split())} words generated)")
            print("="*55)
            return closing_statement
        except Exception as e:
            print(f"   ‚ùå ERROR generating {role} closing argument: {e}")
            error_msg = f"[Error generating closing argument for {role}: {e}]"
            self.debate_history.append({"role": role, "content": error_msg})
            return error_msg

    # ** NEW: Method for Judge's Verdict **
    def generate_judge_verdict(self):
        """Generates a verdict from the neutral Judge AI."""
        print(f"\n{'='*10} ‚öñÔ∏è Generating Judge's Verdict {'='*10}")

        # Prepare the full transcript, including closing arguments
        full_transcript = f"Debate Topic: {self.current_topic}\n\n"
        for entry in self.debate_history: # History now includes closing args
            full_transcript += f"--- {entry['role'].upper()} ---\n{entry['content']}\n\n"

        # Limit transcript length if extremely long (adjust as needed)
        max_transcript_len = 20000 # Generous limit for judge
        if len(full_transcript) > max_transcript_len:
             # Simple truncation, could be smarter (e.g., summarize middle turns)
             print("   ‚ö†Ô∏è Transcript too long for Judge prompt, truncating...")
             full_transcript = full_transcript[:max_transcript_len] + "\n... (Full Transcript Truncated)"


        prompt = f"""
        You are the impartial Judge. Below is the full transcript of the political debate on "{self.current_topic}".

        --- FULL DEBATE TRANSCRIPT START ---
        {full_transcript}
        --- FULL DEBATE TRANSCRIPT END ---

        Your Task:
        Evaluate the performance of the Leftist and Conservative participants based *only* on the following criteria:
        1. Logical Consistency: Were arguments free from contradictions?
        2. Use of Evidence (within the debate): How well was presented information (research snippets, claims) used?
        3. Responsiveness & Refutation: Were opponent's points directly addressed and effectively countered?
        4. Clarity & Structure: Were arguments clear and well-organized?

        Instructions:
        1. Analyze the transcript based *only* on the criteria above. Do not inject personal opinions about the topic.
        2. Write a verdict explaining your evaluation.
        3. Declare which side presented the stronger case *according to the criteria* and provide specific reasons, citing examples from the transcript if possible. Mention key strengths and weaknesses of both sides.
        4. Maintain a strictly neutral and analytical tone.
        5. Aim for a verdict of around 500-750 words.
        6. **Format your verdict using paragraphs for readability.**

        Generate your verdict now:
        """
        try:
            # Use the judge model directly with generate_content
            response = self.judge_model.generate_content(prompt)
            verdict = response.text

            # Append verdict to history with a specific role
            self.debate_history.append({"role": "judge", "content": verdict})
            print(f"\n--- ‚öñÔ∏è JUDGE'S VERDICT ---")
            print(verdict)
            print("="*55)
            return verdict
        except Exception as e:
            print(f"   ‚ùå ERROR generating Judge's verdict: {e}")
            error_msg = f"[Error generating Judge's verdict: {e}]"
            # Optionally add error to history
            self.debate_history.append({"role": "judge", "content": error_msg})
            return error_msg


    def run_debate(self, turns: int = 3):
        """Run the debate turns, then closing arguments, then judge's verdict."""
        if not self.current_topic: print("‚ùå ERROR: Please set a topic first using set_topic()"); return []
        if not isinstance(turns, int) or turns <= 0: print(f"‚ùå ERROR: Invalid number of turns specified ({turns}). Must be a positive integer."); return []

        print(f"\n{'='*15} Starting Debate: {turns} Turns Per Side {'='*15}")
        results = []
        total_responses = turns * 2
        debate_successful = True # Flag to track if main debate completes

        # --- Main Debate Turns ---
        for i in range(total_responses):
            turn_number = (i // 2) + 1
            expected_role = "leftist" if i % 2 == 0 else "conservative"
            side_display_name = expected_role.capitalize()

            if self.current_turn != expected_role:
                print(f"   ‚ö†Ô∏è Turn sequence mismatch! Expected {expected_role}, but simulator is on {self.current_turn}. Correcting...")
                self.current_turn = expected_role

            print(f"\n>>> Starting Debate Turn {turn_number} ({side_display_name} Response {i+1}/{total_responses}) <<<")

            turn_result = self.next_turn()
            # Check for actual content and absence of error markers
            if turn_result and turn_result.get("content") and \
               "[Model" not in turn_result["content"] and \
               "[Prompt Blocked" not in turn_result["content"] and \
               "[Error generating" not in turn_result["content"]:
                results.append(turn_result)
            else:
                 print(f"   ‚ö†Ô∏è Turn {turn_number} ({side_display_name}) failed to generate a valid response or was blocked. Stopping debate.")
                 debate_successful = False
                 break # Stop if a turn fails or is blocked

            if i < total_responses - 1:
                print(f"\n--- ‚è±Ô∏è Waiting {self.config['debate_delay']} seconds before next turn ({self.current_turn.upper()}'s response) ---")
                time.sleep(self.config['debate_delay'])

        if debate_successful:
            print(f"\n{'='*15} Main Debate Rounds Concluded {'='*15}")

            # --- Closing Arguments ---
            # Determine order (e.g., loser of last turn goes first, or fixed order)
            # Let's use a fixed order: Leftist then Conservative
            self.generate_closing_argument("leftist")
            time.sleep(self.config['debate_delay']) # Pause before next closing arg
            self.generate_closing_argument("conservative")

            # --- Judge's Verdict ---
            time.sleep(self.config['debate_delay']) # Pause before verdict
            self.generate_judge_verdict()

        else:
            print(f"\n{'='*15} Debate Stopped Early Due To Errors {'='*15}")


        # Save final history including closing args and verdict (if generated)
        self.save_debate()
        return results # Return results from main debate turns only


    def save_debate(self, filename: str = None):
        """Save the current debate history and config to a JSON file."""
        # (Implementation remains the same - saves entire self.debate_history)
        if not self.debate_history: print("   ‚ÑπÔ∏è No debate history to save."); return None
        if not filename:
            topic_slug = self.current_topic or "untitled_debate"
            valid_chars = "-_.() %s%s" % (string.ascii_letters, string.digits)
            topic_slug = ''.join(c for c in topic_slug if c in valid_chars)
            topic_slug = topic_slug.replace(' ', '_').lower()[:40]
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"debate_{topic_slug}_{timestamp}.json"
        debate_data = {
            "topic": self.current_topic, "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "config_summary": {k: v for k, v in self.config.items() if 'prompt' not in k},
            "history": self.debate_history, } # Includes closing args and verdict now
        try:
            print(f"\n--- üíæ Saving full debate log to: {filename} ---")
            with open(filename, "w", encoding='utf-8') as f: json.dump(debate_data, f, indent=2, ensure_ascii=False)
            print("--- ‚úÖ Debate log saved successfully ---")
            return filename
        except IOError as e: print(f"‚ùå ERROR saving debate log: {e}"); return None
        except Exception as e: print(f"‚ùå An unexpected error occurred while saving debate log: {e}"); return None

    def get_debate_transcript(self, format_type: str = "text"):
        """Get a formatted transcript of the debate (text, markdown, or basic html)."""
        if not self.debate_history: return "No debate has been conducted yet."
        print(f"\n--- üìÑ Generating {format_type.upper()} transcript ---")
        transcript = ""
        if format_type == "html":
            transcript += "<!DOCTYPE html>\n<html lang='en'>\n<head>\n<meta charset='UTF-8'>\n"
            transcript += f"<title>Debate: {self.current_topic}</title>\n"
            transcript += "<style>\n" # Basic styles
            transcript += " body { font-family: sans-serif; line-height: 1.6; margin: 20px; max-width: 800px; margin-left: auto; margin-right: auto; padding: 1em;}\n"
            transcript += " h1 { text-align: center; border-bottom: 1px solid #ccc; padding-bottom: 10px; margin-bottom: 20px; }\n"
            transcript += " .turn { margin-bottom: 20px; padding: 15px; border-radius: 8px; border: 1px solid #ddd; box-shadow: 2px 2px 5px rgba(0,0,0,0.1); }\n"
            transcript += " .leftist-response { background-color: #eef; border-left: 5px solid #66f; }\n"
            transcript += " .conservative-response { background-color: #fee; border-left: 5px solid #f66; }\n"
            transcript += " .judge-response { background-color: #efe; border-left: 5px solid #0a0; margin-top: 30px; }\n" # Judge style
            transcript += " h3 { margin-top: 0; margin-bottom: 10px; font-size: 1.1em; }\n"
            transcript += " p { margin-top: 0; margin-bottom: 0; white-space: pre-wrap; } \n"
            transcript += " .timestamp { font-size: 0.8em; color: #777; text-align: center; margin-top: 30px; }\n"
            transcript += "</style>\n</head>\n<body>\n"
            transcript += f"<h1>Political Debate: {self.current_topic}</h1>\n\n"
            for entry in self.debate_history:
                role = entry["role"].capitalize()
                content = entry["content"].replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                # Assign CSS class based on role
                if entry["role"] == "leftist": css_class = "leftist-response"
                elif entry["role"] == "conservative": css_class = "conservative-response"
                elif entry["role"] == "judge": css_class = "judge-response"
                else: css_class = "" # Default fallback
                transcript += f'<div class="turn {css_class}">\n  <h3>{role}</h3>\n  <p>{content}</p>\n</div>\n\n'
            transcript += f"<div class='timestamp'>Transcript generated: {time.strftime('%Y-%m-%d %H:%M:%S')}</div>\n"
            transcript += "</body>\n</html>"
            return transcript
        elif format_type == "markdown":
            transcript = f"# Political Debate: {self.current_topic}\n\n"
            for entry in self.debate_history:
                role = entry["role"].capitalize()
                content = entry["content"]
                # Use heading for role, output content directly for paragraphs
                transcript += f"## {role}\n\n{content}\n\n---\n\n"
            return transcript
        else: # Plain text
            transcript = f"POLITICAL DEBATE: {self.current_topic}\n" + "=" * (len(self.current_topic)+18) + "\n\n"
            for entry in self.debate_history:
                role = entry["role"].upper()
                content = entry["content"]
                transcript += f"--- {role} ---\n{content}\n\n"
            return transcript


# ============================
# Main Execution Block
# ============================
if __name__ == "__main__":
    print("\n" + "="*60)
    print("      ü§ñ Welcome to the Political Debate Simulator! ü§ñ")
    print("="*60 + "\n")

    try:
        simulator = PoliticalDebateSimulator()
    except Exception as main_init_error:
         print("\n‚ùå Critical error during simulator initialization. Exiting.")
         exit(1)

    # --- Open-ended topic selection ---
    selected_topic = ""
    while not selected_topic:
        selected_topic = input("Enter the political topic you want the AIs to debate: ").strip()
        if not selected_topic:
            print("   Please enter a topic.")
        elif len(selected_topic) < 5:
             print("   Topic seems too short. Please be more specific.")
             selected_topic = ""

    # --- Turn selection ---
    num_turns_per_side = 0
    while num_turns_per_side <= 0:
        try:
            turns_input = input("Enter number of main debate turns per side (e.g., 3 for 6 total rebuttals, default: 3): ").strip()
            if not turns_input: num_turns_per_side = 3; print("   Using default: 3 turns per side.")
            else:
                 num_turns_per_side = int(turns_input)
                 if num_turns_per_side <= 0: print("   Please enter a positive number.")
                 elif num_turns_per_side > 5: print(f"   Warning: {num_turns_per_side} turns per side plus closing args may be very long/expensive.") # Adjusted warning threshold
        except ValueError: print("   Invalid input.")


    # --- Run simulation (includes closing args and verdict) ---
    try:
        simulator.set_topic(selected_topic)
        # run_debate now handles main turns, closing, and verdict internally
        simulator.run_debate(turns=num_turns_per_side)
    except Exception as run_error:
        print(f"\n‚ùå An error occurred during the debate simulation: {run_error}")
        print("   Attempting to save any history generated so far...")
        simulator.save_debate() # Attempt save even on error

    # --- Transcript options (Save happens within run_debate now) ---
    saved_filename = simulator.save_debate() # Get filename if saved
    if saved_filename and simulator.debate_history:
        print("\n--- Transcript Options ---")
        view_choice = input("View final debate transcript now? (y/n): ").strip().lower()
        if view_choice == 'y':
            format_type = ""
            while format_type not in ["text", "markdown", "html"]:
                format_type = input("Choose format (text/markdown/html, default: text): ").strip().lower() or "text"
            transcript = simulator.get_debate_transcript(format_type=format_type)
            print("\n" + "="*15 + f" DEBATE TRANSCRIPT ({format_type.upper()}) " + "="*15 + "\n")
            print(transcript)
            if format_type == "html":
                 html_filename = saved_filename.replace(".json", ".html")
                 try:
                      with open(html_filename, "w", encoding='utf-8') as f: f.write(transcript)
                      print(f"   ‚ÑπÔ∏è HTML transcript also saved to: {html_filename}")
                 except IOError as e: print(f"   ‚ö†Ô∏è Could not save HTML transcript file: {e}")


    print(f"\n‚úÖ Simulation finished. Full debate log saved to: {saved_filename or 'Not saved'}")
    print("="*60 + "\n")
